{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c746927-8d25-4f3d-b32d-e7f2e0560f51",
   "metadata": {},
   "source": [
    "1> In simple linear regression , there is only one output feature dependent on only one indepentdent feature whereas in multiple linear regression the output feature is dependent on more than one independent features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102ddd70-8121-4dff-8ab8-9db8eadf903b",
   "metadata": {},
   "source": [
    "2> Linear regression makes several assumptions :\n",
    "1) Linearity \n",
    "2) Independence\n",
    "3) Normality\n",
    "4) No multi colinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa557bb6-bdc1-4150-84c3-01e6ab4cf56f",
   "metadata": {},
   "source": [
    "3> The slope is the one which keeps on chaging as we move through the cost function whereas the intercept is the one that remains constant. The slope can be derived by finding the derivative of the function at a point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dac1cd8-0308-4f83-b3f3-f88da6877aea",
   "metadata": {},
   "source": [
    "4> Gradient descent is an optimization algorithm commonly used in machine learning for finding the optimal values of the parameters in a model. It is particularly useful in situations where the model's objective function is differentiable, such as in linear regression or neural networks.\n",
    "\n",
    "    Gradient descent is a fundamental algorithm in machine learning that plays a crucial role in training models by iteratively optimizing their parameters to minimize the objective function and improve their performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864c09d7-7a21-4fca-83f4-f8e58715d13c",
   "metadata": {},
   "source": [
    "5> When the Output is dependent on more than one indepentdent features , we use multi linear regression.\n",
    "\n",
    "    In simple linear regression , there is only one output feature dependent on only one indepentdent feature whereas in multiple linear regression the output feature is dependent on more than one independent features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ede6b6-6bfa-4111-aa17-826a1a8e4804",
   "metadata": {},
   "source": [
    "6> Multicollinearity refers to the presence of high correlation among independent variables in a multiple linear regression model. It occurs when two or more independent variables are highly linearly related, making it difficult to distinguish their individual effects on the dependent variable. Multicollinearity can cause several issues in the regression analysis, including unstable and unreliable coefficient estimates, inflated standard errors, and difficulties in interpreting the importance of individual predictors.\n",
    "\n",
    "    Detecting Multicollinearity:\n",
    "    1) Correlation Matrix\n",
    "    2) Variance Inflation Factor (VIF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18e5aa2-c0b9-4a5f-858b-c59db7eae386",
   "metadata": {},
   "source": [
    "7> Polynomial regression model is used for non linear relations. Polynomial regression is a type of regression analysis that models the relationship between the independent variable(s) and the dependent variable as a polynomial function of a specified degree. It extends the concept of linear regression by allowing for nonlinear relationships between the variables.\n",
    "\n",
    "    The main difference between linear regression and polynomial regression lies in the linearity assumption. In linear regression, the relationship between the independent variables and the dependent variable is assumed to be linear. In polynomial regression, this assumption is relaxed, and the relationship can be nonlinear due to the inclusion of higher-order terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028c706b-0d38-4de7-b345-ace3168b310b",
   "metadata": {},
   "source": [
    "8> Advantages of Polynomial Regression over Linear Regression:\n",
    "\n",
    "Capturing Nonlinear Relationships: Polynomial regression can capture nonlinear relationships between the independent variables and the dependent variable by including higher-order terms. This flexibility allows for a better fit to data that exhibits nonlinear patterns.\n",
    "\n",
    "Improved Model Fit: In cases where the relationship between the variables is truly nonlinear, polynomial regression can provide a better fit to the data compared to linear regression. It can capture more complex patterns and improve the model's predictive performance.\n",
    "\n",
    "Disadvantages of Polynomial Regression compared to Linear Regression:\n",
    "\n",
    "Overfitting: Polynomial regression runs the risk of overfitting the data if the degree of the polynomial is too high. Overfitting occurs when the model fits the training data too closely and fails to generalize well to new, unseen data. Regularization techniques or careful model selection can help mitigate overfitting.\n",
    "\n",
    "Increased Complexity: As the degree of the polynomial increases, the model becomes more complex, making it harder to interpret the individual coefficients. The inclusion of higher-order terms can make the model less intuitive and more challenging to explain.\n",
    "\n",
    "Extrapolation: Polynomial regression models are not well-suited for extrapolation, meaning predicting outside the range of the observed data. Extrapolation can lead to unreliable predictions, especially if the polynomial function diverges significantly from the observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e3a44a-a283-4122-93a7-a4c2595c4bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
